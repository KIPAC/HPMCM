{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f44c5d9f-023b-4351-b7b6-9ba4a5b51b07",
   "metadata": {},
   "source": [
    "## Clean the input shear catalogs\n",
    "\n",
    "This is a simple utility notebook showing how to split and clean the input Shear catalogs.\n",
    "\n",
    "The will take input Shear catalogs that are just the concatanation of the per-patch metadetect processing and 1) do the de-duplication at the \"tract\" and \"patch\" levels, (but not the \"cell\" level unless `clean` is True).\n",
    "\n",
    "If `clean` is false, this will leave sources in a 1\" buffer around the central part of each patch, if it is true it will leave no buffer.\n",
    "\n",
    "*Note this notebook is run on unsplit/uncleaned input file taken directly from concatanating per-patch metadetect files which are not provided as part of the test data*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04c00c4-890c-429f-a588-556f939751f2",
   "metadata": {},
   "source": [
    "#### Standard imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54616a7-94b7-4635-94a0-e883d5349f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tables_io\n",
    "from hpmcm import shear_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee772e42-47f5-4431-a655-bec48151726d",
   "metadata": {},
   "source": [
    "#### Set up the configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b85cc1-0af2-4fd6-be8c-52c4d635b124",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = \"sv38\"                                                # Input data directory\n",
    "shear_value_strs = ['0p0025', '0p005', '0p01', '0p02', '0p04']  # Applied shears as a string\n",
    "shear_values = [0.0025, 0.005, 0.01, 0.02, 0.04]                # Decimal versions of applied shear      \n",
    "cat_types = ['wmom', 'gauss', 'pgauss']                         # which object characterization to use \n",
    "tracts = [10463, 10705]                                         # Tracts to loop over\n",
    "clean = True                                                    # Fully clean patches for de-duplication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8710356-0db7-4e22-9870-3872c2d5a9cb",
   "metadata": {},
   "source": [
    "#### Loop over inputs and run the split and clean function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fd7d69-918c-40d1-ac96-d087f1dd5f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tract_ in tracts:\n",
    "    for shear_st_, shear_ in zip(shear_value_strs, shear_values):\n",
    "        for cat_type_ in cat_types:\n",
    "            outFile = f\"{DATADIR}/shear_{cat_type_}_{shear_st_}.parq\"\n",
    "            print(f\"Running {outFile} {tract_}\")\n",
    "            shear_utils.splitByTypeAndClean(outFile, tract_, shear=shear_, catType=cat_type_, clean=clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ffc583-8548-4f46-bcd0-1e32774243f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3a408f-ef9e-48f3-b9bb-61798889099b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
